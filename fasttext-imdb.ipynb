{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    },
    "colab": {
      "name": "03-fasttext-imdb.ipynb",
      "version": "0.3.2",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1gUPGb6xfqM",
        "colab_type": "text"
      },
      "source": [
        "* fasttext https://arxiv.org/abs/1607.01759\n",
        "* https://github.com/nzw0301/keras-examples/blob/master/fast-text.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCjlc-cHxfqW",
        "colab_type": "code",
        "colab": {},
        "outputId": "a21a0b5a-de5b-4df3-f5ca-bd52fdd4143b"
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Lambda, Embedding, GlobalAveragePooling1D\n",
        "from keras.datasets import imdb\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8n8ekbmxfqo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary_size = 5000\n",
        "embedding_size = 50\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocabulary_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeNU9npCxfqy",
        "colab_type": "code",
        "colab": {},
        "outputId": "19328e4f-510f-4d8c-e741-66439879aba0"
      },
      "source": [
        "print(x_train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 2, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1cyJWzYxfq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word2num = imdb.get_word_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1p49bKwfxfrF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num2word = {v:k for k,v in word2num.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4T53Qr5xfrN",
        "colab_type": "code",
        "colab": {},
        "outputId": "1fe1b2e9-786f-46a6-e628-9db4eb330e07"
      },
      "source": [
        "print(\" - \".join(num2word[x] for x in x_train[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the - as - you - with - out - themselves - powerful - lets - loves - their - becomes - reaching - had - journalist - of - lot - from - anyone - to - have - after - out - atmosphere - never - more - room - and - it - so - heart - shows - to - years - of - every - never - going - and - help - moments - or - of - every - chest - visual - movie - except - her - was - several - of - enough - more - with - is - now - current - film - as - you - of - mine - potentially - unfortunately - of - you - than - him - that - with - out - themselves - her - get - for - was - camp - of - you - movie - sometimes - movie - that - with - scary - but - and - to - story - wonderful - that - in - seeing - in - character - to - of - 70s - and - with - heart - had - shadows - they - of - here - that - with - her - serious - to - have - does - when - from - why - what - have - critics - they - is - you - that - isn't - one - will - very - to - as - itself - with - other - and - in - of - seen - over - and - for - anyone - of - and - br - show's - to - whether - from - than - out - themselves - history - he - name - half - some - br - of - and - odd - was - two - most - of - mean - for - 1 - any - an - boat - she - he - should - is - thought - and - but - of - script - you - not - while - history - he - heart - to - real - at - and - but - when - from - one - bit - then - have - two - of - script - their - with - her - nobody - most - that - with - wasn't - to - with - armed - acting - watch - an - for - with - and - film - want - an\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7AXgBUrxfrV",
        "colab_type": "code",
        "colab": {},
        "outputId": "6f3ad8ef-560b-4c85-ae1f-f5f555a52d98"
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiOYw1Uzxfrf",
        "colab_type": "code",
        "colab": {},
        "outputId": "66488ad2-259f-480a-bc0f-9de38837e166"
      },
      "source": [
        "x_train.shape, x_train.dtype"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((25000,), dtype('O'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eUz0TCexfrl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen = 400\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZIznBr3xfrq",
        "colab_type": "code",
        "colab": {},
        "outputId": "0886955c-341b-4f39-d199-c16c18e836d2"
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    1,   14,   22,   16,   43,\n",
              "        530,  973, 1622, 1385,   65,  458, 4468,   66, 3941,    4,  173,\n",
              "         36,  256,    5,   25,  100,   43,  838,  112,   50,  670,    2,\n",
              "          9,   35,  480,  284,    5,  150,    4,  172,  112,  167,    2,\n",
              "        336,  385,   39,    4,  172, 4536, 1111,   17,  546,   38,   13,\n",
              "        447,    4,  192,   50,   16,    6,  147, 2025,   19,   14,   22,\n",
              "          4, 1920, 4613,  469,    4,   22,   71,   87,   12,   16,   43,\n",
              "        530,   38,   76,   15,   13, 1247,    4,   22,   17,  515,   17,\n",
              "         12,   16,  626,   18,    2,    5,   62,  386,   12,    8,  316,\n",
              "          8,  106,    5,    4, 2223,    2,   16,  480,   66, 3785,   33,\n",
              "          4,  130,   12,   16,   38,  619,    5,   25,  124,   51,   36,\n",
              "        135,   48,   25, 1415,   33,    6,   22,   12,  215,   28,   77,\n",
              "         52,    5,   14,  407,   16,   82,    2,    8,    4,  107,  117,\n",
              "          2,   15,  256,    4,    2,    7, 3766,    5,  723,   36,   71,\n",
              "         43,  530,  476,   26,  400,  317,   46,    7,    4,    2, 1029,\n",
              "         13,  104,   88,    4,  381,   15,  297,   98,   32, 2071,   56,\n",
              "         26,  141,    6,  194,    2,   18,    4,  226,   22,   21,  134,\n",
              "        476,   26,  480,    5,  144,   30,    2,   18,   51,   36,   28,\n",
              "        224,   92,   25,  104,    4,  226,   65,   16,   38, 1334,   88,\n",
              "         12,   16,  283,    5,   16, 4472,  113,  103,   32,   15,   16,\n",
              "          2,   19,  178,   32], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdk_XhCnxfrw",
        "colab_type": "code",
        "colab": {},
        "outputId": "8d5f26f0-f508-471c-8d66-7668af90d648"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocabulary_size, output_dim=embedding_size, embeddings_initializer='glorot_uniform'))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=32,\n",
        "          validation_data=(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/10\n",
            "25000/25000 [==============================] - 2s - loss: 0.6091 - acc: 0.7318 - val_loss: 0.5019 - val_acc: 0.8090\n",
            "Epoch 2/10\n",
            "25000/25000 [==============================] - 1s - loss: 0.4120 - acc: 0.8578 - val_loss: 0.3708 - val_acc: 0.8640\n",
            "Epoch 3/10\n",
            "25000/25000 [==============================] - 1s - loss: 0.3239 - acc: 0.8823 - val_loss: 0.3230 - val_acc: 0.8760\n",
            "Epoch 4/10\n",
            "25000/25000 [==============================] - 1s - loss: 0.2830 - acc: 0.8951 - val_loss: 0.3019 - val_acc: 0.8818\n",
            "Epoch 5/10\n",
            "25000/25000 [==============================] - 1s - loss: 0.2573 - acc: 0.9039 - val_loss: 0.2932 - val_acc: 0.8828\n",
            "Epoch 6/10\n",
            "25000/25000 [==============================] - 1s - loss: 0.2396 - acc: 0.9108 - val_loss: 0.2855 - val_acc: 0.8839\n",
            "Epoch 7/10\n",
            "25000/25000 [==============================] - 2s - loss: 0.2262 - acc: 0.9161 - val_loss: 0.2808 - val_acc: 0.8874\n",
            "Epoch 8/10\n",
            "25000/25000 [==============================] - 1s - loss: 0.2150 - acc: 0.9203 - val_loss: 0.2796 - val_acc: 0.8870\n",
            "Epoch 9/10\n",
            "25000/25000 [==============================] - 1s - loss: 0.2055 - acc: 0.9243 - val_loss: 0.2821 - val_acc: 0.8864\n",
            "Epoch 10/10\n",
            "25000/25000 [==============================] - 1s - loss: 0.1975 - acc: 0.9276 - val_loss: 0.2851 - val_acc: 0.8865\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8650f69f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOghAuYWxfr0",
        "colab_type": "code",
        "colab": {},
        "outputId": "1011fb1d-43c9-45fc-ef60-3187e6b70fd4"
      },
      "source": [
        "score, acc = model.evaluate(x_test, y_test, batch_size=32)\n",
        "print()\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24672/25000 [============================>.] - ETA: 0s\n",
            "Test score: 0.285111816511\n",
            "Test accuracy: 0.88648\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}